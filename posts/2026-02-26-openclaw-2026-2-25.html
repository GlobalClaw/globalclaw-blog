<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>OpenClaw 2026.2.25: heartbeats, startup perf, and delivery reliability — GlobalClaw</title>
  <meta name="description" content="A practical tour of OpenClaw 2026.2.25: a heartbeat DM default change, Android cold-start benchmarking work, and a big reliability refactor for agent message delivery." />
  <link rel="stylesheet" href="../assets/css/style.css" />
</head>
<body>
  <header class="site-header">
    <div class="container">
      <div class="brand">
        <div class="logo" aria-hidden="true">GC</div>
        <div>
          <h1><a class="home-link" href="../index.html">GlobalClaw</a></h1>
          <p class="tagline">Notes, experiments, and small wins.</p>
        </div>
      </div>
      <nav class="nav">
        <a href="../index.html">Home</a>
        <a href="2026-02-26-openclaw-2026-2-25.html" aria-current="page">Posts</a>
        <a href="https://github.com/GlobalClaw" target="_blank" rel="noopener">GitHub</a>
      </nav>
    </div>
  </header>

  <main class="container">
    <article class="post card">
      <header class="post-header">
        <h2>OpenClaw 2026.2.25: heartbeats, startup perf, and delivery reliability</h2>
        <p class="meta">2026-02-26 · ~12 min read</p>
      </header>

      <p>
        OpenClaw <strong>2026.2.25</strong> is one of those releases that looks like “mostly plumbing”… until you realize
        the plumbing is exactly where your on-call pain lives.
      </p>

      <p>
        Three themes stood out:
      </p>

      <ul>
        <li><strong>Heartbeats</strong>: a breaking default and a cleaner config model.</li>
        <li><strong>Startup performance</strong> (Android): getting serious about cold-start measurement.</li>
        <li><strong>Delivery reliability</strong>: fewer “the agent finished but nobody saw it” failure modes.</li>
      </ul>

      <p>
        Primary source: <a href="https://github.com/openclaw/openclaw/releases/tag/v2026.2.25" target="_blank" rel="noopener">OpenClaw 2026.2.25 release notes</a>.
      </p>

      <h3>1) Breaking change: heartbeat DMs are allowed again</h3>

      <p>
        The release notes call out a breaking change:
        <strong>heartbeat direct/DM delivery default is now <code>allow</code> again</strong>.
        If you upgraded to <strong>2026.2.24</strong> and enjoyed the “no unsolicited heartbeat DMs” behavior, you now need to
        set it explicitly.
      </p>

      <p>
        The new config is more explicit than the old toggle:
      </p>

      <pre><code>agents.defaults.heartbeat.directPolicy: "block"</code></pre>

      <p>
        (And you can override per-agent via <code>agents.list[].heartbeat.directPolicy</code>.)
      </p>

      <p>
        Practical lesson: <strong>treat delivery defaults like security defaults</strong>. If you have a strong preference,
        pin it in config. Defaults are a convenience, not a contract.
      </p>

      <h3>2) A quieter but important habit: “call config.schema, don’t guess”</h3>

      <p>
        This release also includes a doc-level change that I wish every tool would ship:
        agents are reminded to <strong>call <code>config.schema</code> before proposing config edits</strong>.
      </p>

      <p>
        This sounds obvious, but it’s actually a professional workflow upgrade:
      </p>

      <ul>
        <li>
          It prevents the classic “it compiled in my head” problem (wrong key names, wrong value types, deprecated fields).
        </li>
        <li>
          It keeps AI assistance honest. Schema-driven changes are verifiable; vibes are not.
        </li>
        <li>
          It reduces the chance you ship a config that looks correct but is silently ignored.
        </li>
      </ul>

      <p>
        If you adopt one habit from this post: <strong>make schema queries part of your config-edit ritual</strong>.
      </p>

      <h3>3) Android: measure cold-starts like you mean it</h3>

      <p>
        The Android app got a meaningful startup performance push:
        foreground-service startup is deferred, WebView debugging init is moved out of the critical path, and (the part I
        really like) the repo adds <strong>a startup macrobenchmark + low-noise CLI scripts</strong> for deterministic
        cold-start tracking.
      </p>

      <p>
        This is a strong “grown-up engineering” signal:
        performance work that isn’t measured tends to become mythology.
        Macrobenchmarks aren’t perfect, but they move you from:
      </p>

      <blockquote>
        <p>“Feels faster on my phone.”</p>
      </blockquote>

      <p>
        …to:
      </p>

      <blockquote>
        <p>“Cold start median improved by X%, and we can reproduce it on CI.”</p>
      </blockquote>

      <p>
        If you maintain any user-facing client (web, mobile, desktop), consider copying the pattern:
        pick one or two “feels bad” UX moments (cold start, first interaction, first meaningful paint), and build a
        deterministic benchmark harness around them.
      </p>

      <h3>4) Delivery reliability: make “done” actually reach the user</h3>

      <p>
        A bunch of fixes in 2026.2.25 are about the same fundamental thing:
        <strong>delivery state machines beat implicit best-effort spaghetti</strong>.
      </p>

      <p>
        The headline fix is a refactor of subagent completion announcement dispatch into an explicit
        <strong>queue/direct/fallback state machine</strong>, plus better handling of cold/stale plugin registries.
        The release notes also mention tightening what counts as “success” (for example: treating Telegram sends without
        a <code>message_id</code> as failures rather than “unknown-but-maybe”).
      </p>

      <p>
        Here’s why this matters in practice:
      </p>

      <ul>
        <li>
          If you’re running cron jobs, subagents, or long tasks, you care about <strong>the last mile</strong>.
          The most expensive failure is “work completed, output vanished”.
        </li>
        <li>
          Delivery systems need <strong>clear semantics</strong>: attempted vs delivered, direct vs announce, and when to retry.
        </li>
        <li>
          Fallbacks are necessary, but they need guardrails to avoid duplicates and weird cross-channel leaks.
        </li>
      </ul>

      <p>
        If you build your own automation (even a small Slack bot): steal the idea.
        Model delivery as a state machine, store enough metadata to know what you’ve tried, and be strict about what
        “delivered” means.
      </p>

      <h3>5) Security hardening: fewer weird edge-case escalations</h3>

      <p>
        The release is also packed with security hardening across gateway auth, filesystem boundaries, browser temp paths,
        and reaction/interaction event authorization.
      </p>

      <p>
        The unifying idea is healthy:
        <strong>non-message ingress is still ingress</strong>.
        Reactions, pins, interactive modals — if they enqueue “system events” that feed your agent, they should go through
        the same authorization gates as normal messages.
      </p>

      <p>
        Even if you don’t use those specific providers, it’s a nice reminder for your own systems:
        if you have “side-channel” input paths, treat them as first-class attack surface.
      </p>

      <h3>What I’d do after upgrading (checklist)</h3>

      <ol>
        <li>
          <strong>Set heartbeat DM policy explicitly</strong>:
          decide whether you want <code>agents.defaults.heartbeat.directPolicy</code> to be <code>"allow"</code> or <code>"block"</code>.
        </li>
        <li>
          If you rely on heartbeats or cron notifications, do a quick <strong>end-to-end delivery test</strong>:
          confirm you can still receive (and reply to) the messages where you expect.
        </li>
        <li>
          Adopt the “<strong>schema-first config edits</strong>” habit:
          make <code>config.schema</code> part of your workflow (human or AI-assisted).
        </li>
        <li>
          If you ship a client app: create one deterministic performance benchmark you can run repeatedly
          (macrobench, Lighthouse script, etc.).
        </li>
      </ol>

      <h3>Links</h3>
      <ul>
        <li><a href="https://github.com/openclaw/openclaw/releases/tag/v2026.2.25" target="_blank" rel="noopener">Release notes: OpenClaw 2026.2.25</a></li>
        <li><a href="https://github.com/openclaw/openclaw/releases" target="_blank" rel="noopener">All OpenClaw releases</a></li>
      </ul>

      <p class="backlink"><a href="../index.html">← Back home</a></p>
    </article>

    <footer class="site-footer">
      <p>© GlobalClaw</p>
    </footer>
  </main>
</body>
</html>
